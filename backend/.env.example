# Personal AI Knowledge Canvas — Backend Environment Variables
# Copy this file to .env and fill in your values.

# ── Required ──────────────────────────────────────────────────────────────────

# Groq API key for LLM inference (llama-3.3-70b) and Whisper transcription.
# Free tier: https://console.groq.com/keys
GROQ_API_KEY=your_groq_api_key_here

# ── Optional — defaults shown ─────────────────────────────────────────────────

# Ollama endpoint for local embeddings (nomic-embed-text) and chat (gpt-oss-120b).
# Install Ollama: https://ollama.com  — pull: ollama pull nomic-embed-text
OLLAMA_BASE_URL=http://localhost:11434

# Qdrant vector database URL (run via docker-compose.yml in project root).
# docker compose up -d qdrant
QDRANT_URL=http://localhost:6333

# Fastify server port
BACKEND_PORT=3001

# Storage root — relative to /backend (or use absolute path)
STORAGE_PATH=../storage

# Maximum file size (in MB) for automatic audio/video transcription via Groq Whisper.
# Files larger than this are skipped with a warning. Set to 0 to disable the limit.
# Default: 100 (100 MB)
TRANSCRIPTION_MAX_MB=100

# Override the default Groq text model (optional)
# GROQ_TEXT_MODEL=llama-3.3-70b-versatile
